# DNN_final_template

README â€” Visual Storytelling with Spatial & Cross-Modal Attention

ğŸš€ Overview
This repository explores how attention mechanisms can improve visual storytelling and sequence prediction.

Instead of relying only on a basic CNN encoder, the model learns to:
â€¢	Spatial attention focuses on the meaningful parts of an image

â€¢	Cross-Modal fusion attention connects images and text in a shared space

â€¢	reconstruct sharper visuals and produce more coherent outputs

By enriching visual features and aligning them with language features, the system produces representations that are more informative and easier for downstream tasks.

Attention: CNN encoders compress images into small latent vectors.



ğŸš€ Installation:
   Create a new notebook environment in Google Colab
   
âš™ï¸ Requirements

â€¢	Python 3.8+ versions
â€¢	PyTorch
â€¢	matplotlib
â€¢	numpy
â€¢	torchvision
â€¢	Transformers


ğŸš€ Features

1ï¸âƒ£ Spatial Attention

â€¢	sharpens important areas and includes temperature and gamma controls for more precise focus

2ï¸âƒ£Cross-Modal Fusion Attention

â€¢	It helps the model to learn clear features that understand both the image and the text 

3ï¸âƒ£ Enhanced Loss Strategy

â€¢	L1 Loss -----> preserves edges
â€¢	MSE Loss -----> stabilizes training
â€¢	Perceptual Loss ------> improves textures
â€¢	Edge Loss ------> sharpens contours 



 ğŸš€ HuggingFace Dataset Support:
 
Compatible with datasets containing sequences of images + captions (e.g. daniel3303/StoryReasoning).

Dataset Requirements contains:

â€œcaptionsâ€ -----> list of caption strings
â€œframesâ€ -----> list of PIL images



ğŸ“‚ Project Structure
DNN_final_template/
â”‚

â”œâ”€â”€ experimental_notebook

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ Results

â””â”€â”€ README.md


 ğŸ¤ Contributing
Community contributions are encouraged.
Enhancements such as new attention designs, better fusion strategies, or training                improvements are welcome â€” feel free to open an issue and weâ€™ll plan it together.


  ğŸ“œ License
  

MIT License.

 
